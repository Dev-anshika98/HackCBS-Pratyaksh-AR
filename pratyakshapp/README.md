# Pratyaksh - Argumental Reality Glasses for Hearing Disabilities Mobile Connectivity Application

This folder contains the source code and documentation for our innovative Augmented Reality (AR) based system designed to assist individuals with hearing impairments. Our system provides real-time subtitles for the voices around the user, enhancing their communication and social interactions. Additionally, we have developed a cross-platform mobile application using Flutter, compatible with both Android and iOS devices. This README file provides essential information for setting up and using the AR subtitle system along with the accompanying mobile application.

## Features:

- User can easily connect with their Unique code or Glasses IP Address.
- Seamless integration with AR glasses for a hands-free experience.
- Cross-platform mobile application for managing AR glasses settings.
- Intuitive user interface for easy customization and control.
- Supports the feature to add the Wake Word functionality.

## Apk file:

You can download the .apk file from [here]()

## Installation


To begin using Pratyaksh Application, follow these steps:

1. **Clone the Repository:**
   ```bash
   git clone https://github.com/mukundsolanki/HackCBS-Pratyaksh-AR
   ```

2. **Navigate to the Project Directory:**
   ```bash
   cd pratyakshapp
   ```

3. ***Install Dependencies:***
```bash
 flutter pub get
 ```

4. **Run the Application:**
```bash
flutter run
```

## SCREENSHOTS :


# How does it works?

1. **Connect AR Glasses:**

   Power on your AR glasses and establish a connection with the HearClearly mobile application via Bluetooth or Wi-Fi. Entering the Unique code provided with each pair of AR Glasses.

2. **Launch the Pratyaksh App:**

   Open the Pratyaksh mobile application on your Android or iOS device.

3. **Pair AR Glasses:**

   Follow the on-screen instructions to pair the AR glasses with the mobile application.

4. **Experience Clear Communication:**

   Put on the AR glasses and witness real-time subtitles for the voices around you. And also if the user wants to set any haptic feedback for a particular Wake Word he can easily add the wake word and then the computation power of the glasses will be put in effort to easily identify the words.

   For example, if the user is in any public place and somebody calls his name, So then the user is going to receive haptic feedback regarding the input.